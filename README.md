# Adaptive Music and Gesture-Based Volume Control System  

## Overview  
This project is an **AI-powered music system** that detects **facial expressions** to recommend music and **hand gestures** to control volume. It leverages **machine learning**, **computer vision**, and the **Spotify API** to create a seamless, hands-free user experience.  

## Features  
- ðŸŽµ **Emotion-based music recommendation** using facial expression recognition  
- âœ‹ **Hand gesture-based volume control** for touch-free interaction  
- ðŸ¤– **Real-time processing** with MediaPipe, OpenCV, and machine learning models  
- ðŸŽ§ **Spotify API integration** for music playback  
- ðŸ”§ **Customizable and scalable** for smart homes, accessibility, and interactive media  

## Technologies Used  
- **Python** (main programming language)  
- **MediaPipe & OpenCV** (hand and face tracking)  
- **TensorFlow/Keras** (machine learning models)  
- **Spotify API** (music playback integration)

Usage
Start the application and allow camera access.
Make a hand gesture to adjust the volume.
Facial expressions will determine music recommendations.

License
This project is licensed under the GNU General Public License v3.0. See the LICENSE file for details.

Contributors
Arnav Singh
Anmol Kumar

Acknowledgments
Inspired by computer vision-based gesture recognition research.
Thanks to the open-source community for tools like MediaPipe and TensorFlow.
